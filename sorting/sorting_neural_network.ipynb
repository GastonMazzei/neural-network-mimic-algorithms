{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sorting_neural_network.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z2OtjNM-Kz0s"
      },
      "source": [
        "# <b>Train the Network</b>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EP4sm4gCTTDR",
        "outputId": "295e62af-e882-48bd-dda2-59f5cc99e7ce"
      },
      "source": [
        "#!/usr/bin/python3\n",
        "SEED = 1234\n",
        "\n",
        "import numpy as np\n",
        "np.random.seed(SEED)\n",
        "\n",
        "from numpy.random import randint, choice\n",
        "\n",
        "from keras.models import Sequential\n",
        "#from keras.optimizers import SGD\n",
        "from keras.layers import Dense\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "Nmin, Nmax = 0, 100\n",
        "L = 5\n",
        "Ntot = 100000\n",
        "\n",
        "def preprocess_forward(l: list) -> list:\n",
        "    # recieves a list of integers from Nmin to Nmax\n",
        "    # and returns a list of floats from 0 to 1\n",
        "    return [float(_)/Nmax for _ in l]\n",
        "\n",
        "\n",
        "def preprocess_backward(l: list) -> list:\n",
        "    # recieves a list of floats from 0 to 1\n",
        "    # and returns a list of integers from Nmin to Nmax\n",
        "    return [int(round(_*Nmax)) for _ in l]\n",
        "\n",
        "def compute_correct_value(l: list) -> list:\n",
        "    # recieves a list of integers from Nmin to Nmax\n",
        "    # outputs a list of binaries (0,1) of size L**2\n",
        "    base = [0 for _ in range(L**2)]\n",
        "    l_sorted = np.asarray(sorted(l))\n",
        "    for i,b_i in enumerate(l):\n",
        "        i_local = (l_sorted == b_i).nonzero()[0][0]\n",
        "        base[i * L + i_local] = 1\n",
        "    return base    \n",
        "\n",
        "class NNwork():\n",
        "    def __init__(self, depth: int=3, neurons: int=4, \n",
        "                        activation: str=\"relu\") -> Sequential:\n",
        "        self.network = Sequential([\n",
        "                        Dense(neurons, \n",
        "                              activation=activation,\n",
        "                              ) for _ in range(depth)] +\n",
        "                        [Dense(L**2, activation=\"sigmoid\")])\n",
        "        self.training_history = None\n",
        "\n",
        "    def train(self, train_data, val_data,\n",
        "                    epochs=20, batch_size=32, optimizer=\"sgd\") -> None:\n",
        "        self.network.compile(optimizer=optimizer,\n",
        "                            loss=\"binary_crossentropy\",\n",
        "                            metrics=[\"accuracy\"])\n",
        "        self.training_history = self.network.fit(*train_data, \n",
        "                                        validation_data=val_data,\n",
        "                                        epochs=epochs,\n",
        "                                        batch_size=batch_size).history\n",
        "\n",
        "    def predict(self, x_data):\n",
        "        return self.network.predict(x_data)\n",
        "\n",
        "# Generate the database: \"Ntot\" lists of unrepeated \"L\" numbers each\n",
        "numbers = np.linspace(Nmin, Nmax, Nmax-Nmin+1).astype('int')\n",
        "database = [choice(numbers, L, replace=False).tolist() for _ in range(Ntot)]\n",
        "\n",
        "# Preprocess the database by scaling it\n",
        "preprocessed_database = [preprocess_forward(item) for item in database]\n",
        "\n",
        "# Check the consistency of the pre-post processing operations\n",
        "assert(database==[preprocess_backward(item) for item in preprocessed_database])\n",
        "print(\"\\ninfo: Post(Pre(data)) == data evaluated to True\\n\")\n",
        "\n",
        "# Generate the correct answers by sorting it\n",
        "correct_answers = [compute_correct_value(item) for item in preprocessed_database]\n",
        "\n",
        "# Split into training, validation, and testing\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(preprocessed_database, \n",
        "                                                    correct_answers,\n",
        "                                                    test_size=0.3,\n",
        "                                                    random_state=SEED)\n",
        "X_val, X_test, Y_val, Y_test = train_test_split(X_test, Y_test,\n",
        "                                                test_size=0.5, \n",
        "                                                random_state=SEED)\n",
        "\n",
        "\n",
        "# Instantiate a neural network and train it\n",
        "network = NNwork(depth=4, neurons=32, activation=\"relu\")\n",
        "network.train((X_train, Y_train), (X_val, Y_val),\n",
        "                epochs=100, batch_size=16, optimizer=\"SGD\")\n",
        "\n",
        "# Define a binarizer for predictions\n",
        "def binarizer(ypred):\n",
        "    result = []\n",
        "    for y in ypred:\n",
        "        local_result = [0 for _ in range(L**2)]\n",
        "        for i in range(L):\n",
        "            ix = np.argmax(y[i*L:(i+1)*L])\n",
        "            local_result[i*L+ix] = 1\n",
        "        result += [local_result]\n",
        "    return result\n",
        "\n",
        "\n",
        "# Get predictions over all the datasets to compare with another metric\n",
        "Y_train_pred = binarizer(network.predict(X_train))\n",
        "Y_val_pred = binarizer(network.predict(X_val))\n",
        "Y_test_pred = binarizer(network.predict(X_test))\n",
        "\n",
        "\n",
        "# Define a metric report\n",
        "def report_metric(ytrue, ypred, label):\n",
        "    #convert float [0,1] predictions into binary {0,1}\n",
        "    correct, incorrect = 0,0\n",
        "    print(ytrue[0], ypred[0])\n",
        "    for i,y in enumerate(ytrue):\n",
        "        if i<10:\n",
        "            print(y, ypred[i])\n",
        "        if y==ypred[i]:\n",
        "            correct +=1\n",
        "        else:\n",
        "            incorrect += 1\n",
        "    print(f\"For the '{label}' dataset, accuracy is \"\\\n",
        "            f\"{round(100*correct/(correct+incorrect), 2)}%.\\n\"\\\n",
        "            f\"correct: {correct}\\nINcorrect: {incorrect}\")\n",
        "\n",
        "\n",
        "# Report metrics:\n",
        "report_metric(Y_train, Y_train_pred, label=\"train\")\n",
        "report_metric(Y_val, Y_val_pred, label=\"val\")\n",
        "report_metric(Y_test, Y_test_pred, label=\"test\")\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "info: Post(Pre(data)) == data evaluated to True\n",
            "\n",
            "Epoch 1/100\n",
            "4375/4375 [==============================] - 19s 4ms/step - loss: 0.5348 - accuracy: 0.1380 - val_loss: 0.4959 - val_accuracy: 0.0583\n",
            "Epoch 2/100\n",
            "4375/4375 [==============================] - 13s 3ms/step - loss: 0.4891 - accuracy: 0.0795 - val_loss: 0.4796 - val_accuracy: 0.0343\n",
            "Epoch 3/100\n",
            "4375/4375 [==============================] - 14s 3ms/step - loss: 0.4653 - accuracy: 0.0524 - val_loss: 0.4504 - val_accuracy: 0.0758\n",
            "Epoch 4/100\n",
            "4375/4375 [==============================] - 13s 3ms/step - loss: 0.4406 - accuracy: 0.1033 - val_loss: 0.4319 - val_accuracy: 0.1263\n",
            "Epoch 5/100\n",
            "4375/4375 [==============================] - 14s 3ms/step - loss: 0.4224 - accuracy: 0.1258 - val_loss: 0.4093 - val_accuracy: 0.1191\n",
            "Epoch 6/100\n",
            "4375/4375 [==============================] - 13s 3ms/step - loss: 0.3982 - accuracy: 0.1138 - val_loss: 0.3898 - val_accuracy: 0.1146\n",
            "Epoch 7/100\n",
            "4375/4375 [==============================] - 13s 3ms/step - loss: 0.3830 - accuracy: 0.1227 - val_loss: 0.3749 - val_accuracy: 0.1280\n",
            "Epoch 8/100\n",
            "4375/4375 [==============================] - 14s 3ms/step - loss: 0.3614 - accuracy: 0.1465 - val_loss: 0.3463 - val_accuracy: 0.1620\n",
            "Epoch 9/100\n",
            "4375/4375 [==============================] - 13s 3ms/step - loss: 0.3340 - accuracy: 0.1727 - val_loss: 0.3239 - val_accuracy: 0.1744\n",
            "Epoch 10/100\n",
            "4375/4375 [==============================] - 15s 3ms/step - loss: 0.3156 - accuracy: 0.1789 - val_loss: 0.3079 - val_accuracy: 0.1830\n",
            "Epoch 11/100\n",
            "4375/4375 [==============================] - 15s 3ms/step - loss: 0.2996 - accuracy: 0.1814 - val_loss: 0.2917 - val_accuracy: 0.1858\n",
            "Epoch 12/100\n",
            "4375/4375 [==============================] - 14s 3ms/step - loss: 0.2834 - accuracy: 0.1843 - val_loss: 0.2756 - val_accuracy: 0.1842\n",
            "Epoch 13/100\n",
            "4375/4375 [==============================] - 14s 3ms/step - loss: 0.2675 - accuracy: 0.1867 - val_loss: 0.2601 - val_accuracy: 0.1923\n",
            "Epoch 14/100\n",
            "4375/4375 [==============================] - 15s 3ms/step - loss: 0.2524 - accuracy: 0.1890 - val_loss: 0.2457 - val_accuracy: 0.1886\n",
            "Epoch 15/100\n",
            "4375/4375 [==============================] - 15s 3ms/step - loss: 0.2386 - accuracy: 0.1901 - val_loss: 0.2327 - val_accuracy: 0.1899\n",
            "Epoch 16/100\n",
            "4375/4375 [==============================] - 14s 3ms/step - loss: 0.2264 - accuracy: 0.1924 - val_loss: 0.2212 - val_accuracy: 0.1928\n",
            "Epoch 17/100\n",
            "4375/4375 [==============================] - 14s 3ms/step - loss: 0.2156 - accuracy: 0.1942 - val_loss: 0.2107 - val_accuracy: 0.1948\n",
            "Epoch 18/100\n",
            "4375/4375 [==============================] - 14s 3ms/step - loss: 0.2057 - accuracy: 0.1947 - val_loss: 0.2012 - val_accuracy: 0.1957\n",
            "Epoch 19/100\n",
            "4375/4375 [==============================] - 14s 3ms/step - loss: 0.1965 - accuracy: 0.1957 - val_loss: 0.1924 - val_accuracy: 0.1970\n",
            "Epoch 20/100\n",
            "4375/4375 [==============================] - 14s 3ms/step - loss: 0.1882 - accuracy: 0.1958 - val_loss: 0.1838 - val_accuracy: 0.1960\n",
            "Epoch 21/100\n",
            "4375/4375 [==============================] - 13s 3ms/step - loss: 0.1804 - accuracy: 0.1957 - val_loss: 0.1764 - val_accuracy: 0.1959\n",
            "Epoch 22/100\n",
            "4375/4375 [==============================] - 14s 3ms/step - loss: 0.1732 - accuracy: 0.1958 - val_loss: 0.1697 - val_accuracy: 0.1928\n",
            "Epoch 23/100\n",
            "4375/4375 [==============================] - 14s 3ms/step - loss: 0.1661 - accuracy: 0.1942 - val_loss: 0.1627 - val_accuracy: 0.1922\n",
            "Epoch 24/100\n",
            "4375/4375 [==============================] - 13s 3ms/step - loss: 0.1592 - accuracy: 0.1932 - val_loss: 0.1556 - val_accuracy: 0.1951\n",
            "Epoch 25/100\n",
            "4375/4375 [==============================] - 14s 3ms/step - loss: 0.1525 - accuracy: 0.1915 - val_loss: 0.1498 - val_accuracy: 0.1780\n",
            "Epoch 26/100\n",
            "4375/4375 [==============================] - 14s 3ms/step - loss: 0.1461 - accuracy: 0.1900 - val_loss: 0.1430 - val_accuracy: 0.1802\n",
            "Epoch 27/100\n",
            "4375/4375 [==============================] - 13s 3ms/step - loss: 0.1399 - accuracy: 0.1877 - val_loss: 0.1373 - val_accuracy: 0.1810\n",
            "Epoch 28/100\n",
            "4375/4375 [==============================] - 14s 3ms/step - loss: 0.1340 - accuracy: 0.1862 - val_loss: 0.1322 - val_accuracy: 0.1841\n",
            "Epoch 29/100\n",
            "4375/4375 [==============================] - 14s 3ms/step - loss: 0.1285 - accuracy: 0.1840 - val_loss: 0.1261 - val_accuracy: 0.1802\n",
            "Epoch 30/100\n",
            "4375/4375 [==============================] - 14s 3ms/step - loss: 0.1234 - accuracy: 0.1829 - val_loss: 0.1213 - val_accuracy: 0.1821\n",
            "Epoch 31/100\n",
            "4375/4375 [==============================] - 14s 3ms/step - loss: 0.1186 - accuracy: 0.1817 - val_loss: 0.1170 - val_accuracy: 0.1795\n",
            "Epoch 32/100\n",
            "4375/4375 [==============================] - 14s 3ms/step - loss: 0.1141 - accuracy: 0.1800 - val_loss: 0.1129 - val_accuracy: 0.1822\n",
            "Epoch 33/100\n",
            "4375/4375 [==============================] - 14s 3ms/step - loss: 0.1098 - accuracy: 0.1789 - val_loss: 0.1084 - val_accuracy: 0.1761\n",
            "Epoch 34/100\n",
            "4375/4375 [==============================] - 14s 3ms/step - loss: 0.1059 - accuracy: 0.1783 - val_loss: 0.1059 - val_accuracy: 0.1681\n",
            "Epoch 35/100\n",
            "4375/4375 [==============================] - 14s 3ms/step - loss: 0.1021 - accuracy: 0.1783 - val_loss: 0.1014 - val_accuracy: 0.1757\n",
            "Epoch 36/100\n",
            "4375/4375 [==============================] - 15s 3ms/step - loss: 0.0985 - accuracy: 0.1777 - val_loss: 0.0979 - val_accuracy: 0.1788\n",
            "Epoch 37/100\n",
            "4375/4375 [==============================] - 15s 3ms/step - loss: 0.0952 - accuracy: 0.1775 - val_loss: 0.0947 - val_accuracy: 0.1792\n",
            "Epoch 38/100\n",
            "4375/4375 [==============================] - 14s 3ms/step - loss: 0.0920 - accuracy: 0.1780 - val_loss: 0.0916 - val_accuracy: 0.1817\n",
            "Epoch 39/100\n",
            "4375/4375 [==============================] - 14s 3ms/step - loss: 0.0890 - accuracy: 0.1784 - val_loss: 0.0888 - val_accuracy: 0.1745\n",
            "Epoch 40/100\n",
            "4375/4375 [==============================] - 14s 3ms/step - loss: 0.0864 - accuracy: 0.1793 - val_loss: 0.0857 - val_accuracy: 0.1769\n",
            "Epoch 41/100\n",
            "4375/4375 [==============================] - 14s 3ms/step - loss: 0.0837 - accuracy: 0.1792 - val_loss: 0.0835 - val_accuracy: 0.1845\n",
            "Epoch 42/100\n",
            "4375/4375 [==============================] - 14s 3ms/step - loss: 0.0813 - accuracy: 0.1811 - val_loss: 0.0818 - val_accuracy: 0.1805\n",
            "Epoch 43/100\n",
            "4375/4375 [==============================] - 15s 3ms/step - loss: 0.0792 - accuracy: 0.1805 - val_loss: 0.0789 - val_accuracy: 0.1864\n",
            "Epoch 44/100\n",
            "4375/4375 [==============================] - 14s 3ms/step - loss: 0.0769 - accuracy: 0.1817 - val_loss: 0.0770 - val_accuracy: 0.1850\n",
            "Epoch 45/100\n",
            "4375/4375 [==============================] - 14s 3ms/step - loss: 0.0750 - accuracy: 0.1823 - val_loss: 0.0750 - val_accuracy: 0.1839\n",
            "Epoch 46/100\n",
            "4375/4375 [==============================] - 14s 3ms/step - loss: 0.0731 - accuracy: 0.1834 - val_loss: 0.0729 - val_accuracy: 0.1793\n",
            "Epoch 47/100\n",
            "4375/4375 [==============================] - 14s 3ms/step - loss: 0.0712 - accuracy: 0.1844 - val_loss: 0.0715 - val_accuracy: 0.1926\n",
            "Epoch 48/100\n",
            "4375/4375 [==============================] - 15s 3ms/step - loss: 0.0696 - accuracy: 0.1855 - val_loss: 0.0690 - val_accuracy: 0.1841\n",
            "Epoch 49/100\n",
            "4375/4375 [==============================] - 14s 3ms/step - loss: 0.0680 - accuracy: 0.1863 - val_loss: 0.0671 - val_accuracy: 0.1887\n",
            "Epoch 50/100\n",
            "4375/4375 [==============================] - 15s 3ms/step - loss: 0.0663 - accuracy: 0.1876 - val_loss: 0.0672 - val_accuracy: 0.1836\n",
            "Epoch 51/100\n",
            "4375/4375 [==============================] - 14s 3ms/step - loss: 0.0648 - accuracy: 0.1888 - val_loss: 0.0643 - val_accuracy: 0.1899\n",
            "Epoch 52/100\n",
            "4375/4375 [==============================] - 14s 3ms/step - loss: 0.0634 - accuracy: 0.1891 - val_loss: 0.0628 - val_accuracy: 0.1864\n",
            "Epoch 53/100\n",
            "4375/4375 [==============================] - 15s 3ms/step - loss: 0.0619 - accuracy: 0.1906 - val_loss: 0.0623 - val_accuracy: 0.1861\n",
            "Epoch 54/100\n",
            "4375/4375 [==============================] - 15s 3ms/step - loss: 0.0607 - accuracy: 0.1915 - val_loss: 0.0617 - val_accuracy: 0.1861\n",
            "Epoch 55/100\n",
            "4375/4375 [==============================] - 15s 3ms/step - loss: 0.0594 - accuracy: 0.1921 - val_loss: 0.0599 - val_accuracy: 0.1911\n",
            "Epoch 56/100\n",
            "4375/4375 [==============================] - 14s 3ms/step - loss: 0.0582 - accuracy: 0.1934 - val_loss: 0.0577 - val_accuracy: 0.1962\n",
            "Epoch 57/100\n",
            "4375/4375 [==============================] - 13s 3ms/step - loss: 0.0569 - accuracy: 0.1947 - val_loss: 0.0563 - val_accuracy: 0.1941\n",
            "Epoch 58/100\n",
            "4375/4375 [==============================] - 14s 3ms/step - loss: 0.0557 - accuracy: 0.1949 - val_loss: 0.0559 - val_accuracy: 0.1890\n",
            "Epoch 59/100\n",
            "4375/4375 [==============================] - 14s 3ms/step - loss: 0.0546 - accuracy: 0.1956 - val_loss: 0.0539 - val_accuracy: 0.1934\n",
            "Epoch 60/100\n",
            "4375/4375 [==============================] - 14s 3ms/step - loss: 0.0534 - accuracy: 0.1962 - val_loss: 0.0536 - val_accuracy: 0.1985\n",
            "Epoch 61/100\n",
            "4375/4375 [==============================] - 15s 3ms/step - loss: 0.0524 - accuracy: 0.1971 - val_loss: 0.0527 - val_accuracy: 0.1939\n",
            "Epoch 62/100\n",
            "4375/4375 [==============================] - 14s 3ms/step - loss: 0.0514 - accuracy: 0.1970 - val_loss: 0.0515 - val_accuracy: 0.1971\n",
            "Epoch 63/100\n",
            "4375/4375 [==============================] - 14s 3ms/step - loss: 0.0504 - accuracy: 0.1981 - val_loss: 0.0495 - val_accuracy: 0.2023\n",
            "Epoch 64/100\n",
            "4375/4375 [==============================] - 13s 3ms/step - loss: 0.0493 - accuracy: 0.1989 - val_loss: 0.0487 - val_accuracy: 0.1911\n",
            "Epoch 65/100\n",
            "4375/4375 [==============================] - 14s 3ms/step - loss: 0.0486 - accuracy: 0.1996 - val_loss: 0.0487 - val_accuracy: 0.2010\n",
            "Epoch 66/100\n",
            "4375/4375 [==============================] - 14s 3ms/step - loss: 0.0476 - accuracy: 0.2001 - val_loss: 0.0467 - val_accuracy: 0.1935\n",
            "Epoch 67/100\n",
            "4375/4375 [==============================] - 14s 3ms/step - loss: 0.0468 - accuracy: 0.2004 - val_loss: 0.0465 - val_accuracy: 0.1954\n",
            "Epoch 68/100\n",
            "4375/4375 [==============================] - 14s 3ms/step - loss: 0.0460 - accuracy: 0.2015 - val_loss: 0.0461 - val_accuracy: 0.2013\n",
            "Epoch 69/100\n",
            "4375/4375 [==============================] - 15s 3ms/step - loss: 0.0452 - accuracy: 0.2012 - val_loss: 0.0452 - val_accuracy: 0.2024\n",
            "Epoch 70/100\n",
            "4375/4375 [==============================] - 14s 3ms/step - loss: 0.0444 - accuracy: 0.2005 - val_loss: 0.0434 - val_accuracy: 0.2046\n",
            "Epoch 71/100\n",
            "4375/4375 [==============================] - 15s 3ms/step - loss: 0.0437 - accuracy: 0.2012 - val_loss: 0.0420 - val_accuracy: 0.2062\n",
            "Epoch 72/100\n",
            "4375/4375 [==============================] - 13s 3ms/step - loss: 0.0430 - accuracy: 0.2024 - val_loss: 0.0439 - val_accuracy: 0.2044\n",
            "Epoch 73/100\n",
            "4375/4375 [==============================] - 14s 3ms/step - loss: 0.0422 - accuracy: 0.2024 - val_loss: 0.0420 - val_accuracy: 0.2003\n",
            "Epoch 74/100\n",
            "4375/4375 [==============================] - 14s 3ms/step - loss: 0.0415 - accuracy: 0.2028 - val_loss: 0.0410 - val_accuracy: 0.1993\n",
            "Epoch 75/100\n",
            "4375/4375 [==============================] - 15s 3ms/step - loss: 0.0409 - accuracy: 0.2029 - val_loss: 0.0422 - val_accuracy: 0.2039\n",
            "Epoch 76/100\n",
            "4375/4375 [==============================] - 14s 3ms/step - loss: 0.0402 - accuracy: 0.2025 - val_loss: 0.0409 - val_accuracy: 0.1978\n",
            "Epoch 77/100\n",
            "4375/4375 [==============================] - 14s 3ms/step - loss: 0.0396 - accuracy: 0.2035 - val_loss: 0.0404 - val_accuracy: 0.2000\n",
            "Epoch 78/100\n",
            "4375/4375 [==============================] - 15s 3ms/step - loss: 0.0390 - accuracy: 0.2023 - val_loss: 0.0384 - val_accuracy: 0.1998\n",
            "Epoch 79/100\n",
            "4375/4375 [==============================] - 14s 3ms/step - loss: 0.0384 - accuracy: 0.2030 - val_loss: 0.0396 - val_accuracy: 0.2087\n",
            "Epoch 80/100\n",
            "4375/4375 [==============================] - 13s 3ms/step - loss: 0.0378 - accuracy: 0.2024 - val_loss: 0.0373 - val_accuracy: 0.2096\n",
            "Epoch 81/100\n",
            "4375/4375 [==============================] - 13s 3ms/step - loss: 0.0372 - accuracy: 0.2026 - val_loss: 0.0379 - val_accuracy: 0.2052\n",
            "Epoch 82/100\n",
            "4375/4375 [==============================] - 14s 3ms/step - loss: 0.0367 - accuracy: 0.2027 - val_loss: 0.0356 - val_accuracy: 0.2028\n",
            "Epoch 83/100\n",
            "4375/4375 [==============================] - 14s 3ms/step - loss: 0.0362 - accuracy: 0.2024 - val_loss: 0.0355 - val_accuracy: 0.2030\n",
            "Epoch 84/100\n",
            "4375/4375 [==============================] - 13s 3ms/step - loss: 0.0356 - accuracy: 0.2032 - val_loss: 0.0361 - val_accuracy: 0.2067\n",
            "Epoch 85/100\n",
            "4375/4375 [==============================] - 14s 3ms/step - loss: 0.0351 - accuracy: 0.2029 - val_loss: 0.0343 - val_accuracy: 0.2043\n",
            "Epoch 86/100\n",
            "4375/4375 [==============================] - 15s 3ms/step - loss: 0.0346 - accuracy: 0.2026 - val_loss: 0.0340 - val_accuracy: 0.1987\n",
            "Epoch 87/100\n",
            "4375/4375 [==============================] - 15s 3ms/step - loss: 0.0342 - accuracy: 0.2028 - val_loss: 0.0340 - val_accuracy: 0.2083\n",
            "Epoch 88/100\n",
            "4375/4375 [==============================] - 14s 3ms/step - loss: 0.0336 - accuracy: 0.2034 - val_loss: 0.0330 - val_accuracy: 0.2024\n",
            "Epoch 89/100\n",
            "4375/4375 [==============================] - 13s 3ms/step - loss: 0.0332 - accuracy: 0.2035 - val_loss: 0.0331 - val_accuracy: 0.2035\n",
            "Epoch 90/100\n",
            "4375/4375 [==============================] - 13s 3ms/step - loss: 0.0327 - accuracy: 0.2031 - val_loss: 0.0326 - val_accuracy: 0.2011\n",
            "Epoch 91/100\n",
            "4375/4375 [==============================] - 14s 3ms/step - loss: 0.0323 - accuracy: 0.2041 - val_loss: 0.0328 - val_accuracy: 0.2016\n",
            "Epoch 92/100\n",
            "4375/4375 [==============================] - 13s 3ms/step - loss: 0.0318 - accuracy: 0.2034 - val_loss: 0.0319 - val_accuracy: 0.2117\n",
            "Epoch 93/100\n",
            "4375/4375 [==============================] - 14s 3ms/step - loss: 0.0313 - accuracy: 0.2032 - val_loss: 0.0316 - val_accuracy: 0.2050\n",
            "Epoch 94/100\n",
            "4375/4375 [==============================] - 15s 3ms/step - loss: 0.0309 - accuracy: 0.2032 - val_loss: 0.0302 - val_accuracy: 0.2061\n",
            "Epoch 95/100\n",
            "4375/4375 [==============================] - 13s 3ms/step - loss: 0.0305 - accuracy: 0.2035 - val_loss: 0.0324 - val_accuracy: 0.2030\n",
            "Epoch 96/100\n",
            "4375/4375 [==============================] - 14s 3ms/step - loss: 0.0301 - accuracy: 0.2036 - val_loss: 0.0298 - val_accuracy: 0.2044\n",
            "Epoch 97/100\n",
            "4375/4375 [==============================] - 15s 3ms/step - loss: 0.0297 - accuracy: 0.2042 - val_loss: 0.0302 - val_accuracy: 0.2063\n",
            "Epoch 98/100\n",
            "4375/4375 [==============================] - 13s 3ms/step - loss: 0.0294 - accuracy: 0.2038 - val_loss: 0.0286 - val_accuracy: 0.2006\n",
            "Epoch 99/100\n",
            "4375/4375 [==============================] - 14s 3ms/step - loss: 0.0291 - accuracy: 0.2033 - val_loss: 0.0297 - val_accuracy: 0.1998\n",
            "Epoch 100/100\n",
            "4375/4375 [==============================] - 15s 3ms/step - loss: 0.0286 - accuracy: 0.2041 - val_loss: 0.0283 - val_accuracy: 0.2025\n",
            "[1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0] [1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "[1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0] [1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "[1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0] [1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0]\n",
            "[1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0] [1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "[0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0] [0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0]\n",
            "[0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0] [0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "[0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0] [0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
            "[0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0] [0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0]\n",
            "[1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1] [1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1]\n",
            "[0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0] [0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0]\n",
            "[0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0] [0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0]\n",
            "For the 'train' dataset, accuracy is 92.9%.\n",
            "correct: 65028\n",
            "INcorrect: 4972\n",
            "[0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0] [0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0]\n",
            "[0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0] [0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0]\n",
            "[0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0] [0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0]\n",
            "[0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0] [0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]\n",
            "[0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0] [0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
            "[1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0] [1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0]\n",
            "[0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0] [0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0]\n",
            "[0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0] [0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "[0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0] [0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0]\n",
            "[0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0] [0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
            "[0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0] [0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0]\n",
            "For the 'val' dataset, accuracy is 92.57%.\n",
            "correct: 13886\n",
            "INcorrect: 1114\n",
            "[0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0] [0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0]\n",
            "[0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0] [0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0]\n",
            "[0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0] [0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]\n",
            "[1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0] [1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0]\n",
            "[1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0] [1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0]\n",
            "[0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0] [0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0]\n",
            "[0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0] [0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0] [0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0]\n",
            "[0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0] [0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "[1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0] [1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0]\n",
            "[1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0] [1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0]\n",
            "For the 'test' dataset, accuracy is 92.0%.\n",
            "correct: 13800\n",
            "INcorrect: 1200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZT-G1aPK5fX"
      },
      "source": [
        "# <b>Try the network</b>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJizh-eIVTII"
      },
      "source": [
        "# Define an utility function\n",
        "def transform_prediction_ordering(x, nnetwork):\n",
        "  ypred = binarizer(nnetwork.predict([preprocess_forward(x)]))[0]\n",
        "  result = [-1 for _ in range(L)]\n",
        "  for i in range(L):\n",
        "    result[np.argmax(ypred[i*L:(i+1)*L])] = x[i]\n",
        "  return result"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X40yHrUCJ26S",
        "outputId": "ff70765a-dd02-40c5-df1b-e1a6ea7fab03"
      },
      "source": [
        "# Define lists to be tested\n",
        "TEST_LISTS = [[16,20,6,4,12],\n",
        "              [23,0,44,79,6],\n",
        "              [18,64,5,92,88],\n",
        "              [2,19,12,42,5]]\n",
        "\n",
        "for TEST_LIST in TEST_LISTS:\n",
        "  NETWORK_RESULT = transform_prediction_ordering(TEST_LIST, network)\n",
        "  # Print the results\n",
        "  print(f'We gave the network:\\n{TEST_LIST}\\nand it returned the following list:\\n{NETWORK_RESULT}\\n\\n')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We gave the network:\n",
            "[16, 20, 6, 4, 12]\n",
            "and it returned the following list:\n",
            "[4, 6, 12, 16, 20]\n",
            "\n",
            "\n",
            "We gave the network:\n",
            "[23, 0, 44, 79, 6]\n",
            "and it returned the following list:\n",
            "[0, 6, 23, 44, 79]\n",
            "\n",
            "\n",
            "We gave the network:\n",
            "[18, 64, 5, 92, 88]\n",
            "and it returned the following list:\n",
            "[5, 18, 64, 88, 92]\n",
            "\n",
            "\n",
            "We gave the network:\n",
            "[2, 19, 12, 42, 5]\n",
            "and it returned the following list:\n",
            "[2, 5, 12, 19, 42]\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YUSWO-GLYeC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}